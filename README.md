# SparseD: Sparse Attention for Diffusion Language Models

![demo](https://github.com/user-attachments/assets/4752b94c-16c5-43fc-aa80-a3a2164f363e)


> **SparseD: Sparse Attention for Diffusion Language Models**   ü•Ø[[Arxiv]](https://arxiv.org/abs/2509.24014)   
> [Zeqing Wang](https://inv-wzq.github.io/)<sup>1</sup>, [Gongfan Fang](https://fangggf.github.io/)<sup>1</sup>, [Xinyin Ma](https://horseee.github.io/)<sup>1</sup> , [Xingyi Yang](https://adamdad.github.io/)<sup>2</sup> , [Xinchao Wang](https://sites.google.com/site/sitexinchaowang/)<sup>1</sup>    
> <sup>1</sup> [xML Lab](https://sites.google.com/view/xml-nus), National University of Singapore  
> <sup>2</sup> The Hong Kong Polytechnic University

## üìö Introduction
**SparseD** is a novel sparse attention method for diffusion language models (DLMs), delivering near **lossless acceleration** in performance. It uses full attention and computes sparse patterns during early denoising steps, then reuses these patterns in later steps to restrict computation and improve efficiency. Extensive experiments show that SparseD greatly maintains accuracy on the evaluated benchmarks while achieving up to $1.50\times$ speedup at a 64k context length with 1,024 steps.

<div align="center">
  <img src="assets/SparseD.jpg" width="70%" ></img>
  <br>
  <em>
      The overview of SparseD
  </em>
</div>
<br>

## üõ†Ô∏è Setup
```bash
conda create -n SparseD python=3.10
conda activate SparseD
pip install -r requirements.txt
```

## üöÄ Usage

```bash
# For Dream Model
python dream_generation.py --origin   
python dream_generation.py --skip 0.2 --select 0.3 --block_size 128 --prompt 4k
python dream_generation.py --skip 0.2 --select 0.5 --block_size 32 --prompt short_context

# For LLaDA Model
python llada_generation.py --origin 
python llada_generation.py --skip 0.2 --select 0.3 --block_size 128 --prompt 4k
python llada_generation.py --skip 0.2 --select 0.5 --block_size 32 --prompt short_context
```

Arguments:
- `--model_path`: The model path, e.g., Dream-org/Dream-v0-Instruct-7B and GSAI-ML/LLaDA-1.5 .
- `--seq_len`, `--steps`, `--block_length`, `--sampling-alg`: The inference configuration for diffusion generation. `block_length` refers specifically to the LLaDA model.
- `--origin`: Inference by original model.
- `--skip`, `--select`, `--block_size`: The inference configuration for SparseD. `skip` denotes the ratio of full attention applied to the earlier steps across all denoising steps, `select` denotes the selection ratio for sparse attention, and `block_size` specifies the block size used when selecting important query-key pairs.
- `--prompt`: Choose prompt for simple test, including `["short_context", "4k", "8k", "16k", "32k", "64k"]` length versions.

## üìë Results
### 1. Accuracy 
<div align="center">
<img width="80%" alt="image" src="assets/acc_result.png">
</div>

### 2. Latency
<div align="center">
<img width="80%" alt="image" src="assets/latency_result.png">
</div>

## ‚òÄÔ∏è Note 
- Since our sparse attention is implemented by FlexAttention, we recommend conducting a warm-up inference first, as subsequent inferences will perform better in terms of speed.

- To better demonstrate the acceleration achieved by SparseD, we recommend evaluating it with long-context prompts, such as those with lengths of 16k, 32k, and 64k. We also provide short context for simple evaluation.

## ü§ì Acknowledgments
Our sparse attention is accelerated by [FlexAttention](https://arxiv.org/abs/2412.05496), and implemented on [Dream](https://github.com/DreamLM/Dream) and [LLaDA](https://github.com/ML-GSAI/LLaDA). We extend our gratitude to the community for their valuable contributions!

## üîó Citation
```
@misc{wang2025sparsedsparseattentiondiffusion,
      title={SparseD: Sparse Attention for Diffusion Language Models}, 
      author={Zeqing Wang and Gongfan Fang and Xinyin Ma and Xingyi Yang and Xinchao Wang},
      year={2025},
      eprint={2509.24014},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.24014}, 
}
```
